{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a93dae",
   "metadata": {},
   "source": [
    "# Stance Detection in Political Debates Using Deep Learning Techniques I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58373fb5",
   "metadata": {},
   "source": [
    "This is a follow up notebook to the data used in Somasundaran & Wiebe 2010. Contrasting with the first notebook we do not use traditional ML techniques but instead train a DL model on the data using Flair and Google Colab.\n",
    "\n",
    "Flair: https://github.com/flairNLP/flair\n",
    "\n",
    "Google Colab: https://colab.research.google.com/?utm_source=scs-index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b2f102",
   "metadata": {},
   "source": [
    "The data can be downloaded from:\n",
    "\n",
    "http://mpqa.cs.pitt.edu/corpora/political_debates/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12993788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ClassificationCorpus\n",
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33bbc340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to be adjusted to your platform\n",
    "abortion_data_path = '/home/robin/research/corpora/political_debates_SomasundaranWiebeAcl2009/abortion'\n",
    "gayrights_data_path = '/home/robin/research/corpora/political_debates_SomasundaranWiebeAcl2009/gayRights'\n",
    "\n",
    "train_path = '/home/robin/research/course_pages/stance-detection-st2021/data/train.csv'\n",
    "dev_path = '/home/robin/research/course_pages/stance-detection-st2021/data/dev.csv'\n",
    "test_path = '/home/robin/research/course_pages/stance-detection-st2021/data/test.csv'\n",
    "\n",
    "data_path = '/home/robin/research/course_pages/stance-detection-st2021/data'\n",
    "model_path = '/home/robin/research/course_pages/stance-detection-st2021/models'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4db9de",
   "metadata": {},
   "source": [
    "## 1. Reading in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83821ebe",
   "metadata": {},
   "source": [
    "The following block contains code for reading in the data. Data is read from txt files and joined to strings. In order to train a model using Flair we need to modify the labels a bit. Each label needs to get a tag \"\\_\\_label__\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b2f0827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abortion Data Size: 1082\n",
      "Gay Rights Data Size: 1927\n",
      "Total Data Size: 3009\n"
     ]
    }
   ],
   "source": [
    "# Full vocab list\n",
    "vocab = []\n",
    "\n",
    "# Loading and first preprocessing of abolition data\n",
    "abortion_data = []\n",
    "abortion_stance = []\n",
    "\n",
    "for file in os.listdir(abortion_data_path):\n",
    "    abortion_file_path = os.path.join(abortion_data_path, file)\n",
    "    \n",
    "    with io.open(abortion_file_path, mode='r', encoding='utf-8') as f_in:\n",
    "        \n",
    "        try:\n",
    "            text = []\n",
    "            for line in f_in.read().split('\\n'):\n",
    "                if line.startswith('#stance'):\n",
    "                    abortion_stance.append(int(line[-1]))\n",
    "                elif line.startswith('#'):\n",
    "                    continue\n",
    "                else:\n",
    "                    text.append(line)\n",
    "                                \n",
    "            text = \" \".join(text)\n",
    "            #text = [token.strip() for token in text]\n",
    "            vocab.extend(text.split())\n",
    "            \n",
    "            abortion_data.append(text)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Loading and first preprocessing of gay rights data        \n",
    "gayrights_data = []\n",
    "gayrights_stance = []\n",
    "\n",
    "for file in os.listdir(gayrights_data_path):\n",
    "    gayrights_file_path = os.path.join(gayrights_data_path, file)\n",
    "    \n",
    "    with io.open(gayrights_file_path, mode='r', encoding='utf-8') as f_in:\n",
    "        \n",
    "        try:\n",
    "            text = []\n",
    "            for line in f_in.read().split('\\n'):\n",
    "                if line.startswith('#stance'):\n",
    "                    gayrights_stance.append(int(line[-1]))\n",
    "                elif line.startswith('#'):\n",
    "                    continue\n",
    "                else:\n",
    "                    text.append(line)\n",
    "                        \n",
    "            text = \" \".join(text)\n",
    "            #text = [token.strip() for token in text]\n",
    "            \n",
    "            vocab.extend(text.split())\n",
    "            \n",
    "            gayrights_data.append(text)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "vocab = set(vocab)\n",
    "\n",
    "# __label__ needed for training of model\n",
    "abortion_stance = ['__label__'+str(stance) for stance in abortion_stance]\n",
    "gayrights_stance = ['__label__'+str(stance) for stance in gayrights_stance]\n",
    "        \n",
    "data_total = abortion_data + gayrights_data\n",
    "stance_total = abortion_stance + gayrights_stance\n",
    "\n",
    "abortion_data = pd.Series(abortion_data)\n",
    "abortion_stance = pd.Series(abortion_stance)\n",
    "gayrights_data = pd.Series(gayrights_data)\n",
    "gayrights_stance = pd.Series(gayrights_stance)\n",
    "data_total = pd.Series(data_total)\n",
    "stance_total = pd.Series(stance_total)\n",
    "\n",
    "print(\"Abortion Data Size: {}\".format(len(abortion_data)))\n",
    "print(\"Gay Rights Data Size: {}\".format(len(gayrights_data)))\n",
    "print(\"Total Data Size: {}\".format(len(data_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c92d29ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__label__1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abortion_stance[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2242e2da",
   "metadata": {},
   "source": [
    "## 2. Stratified Data Splitting and Data File Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1787db",
   "metadata": {},
   "source": [
    "We create stratified splits using `StratifiedShuffleSplit`. 'stratified' means that the class distribution is kept intact which is important if the classes are not balanced. \n",
    "\n",
    "`StratifiedShuffleSplit` can be used for cross validation. As we only want to create one split we set `n_splits` to 1. However as we want to create a threeway split (train, development, test) we have to split `X_train` and `y_train` another time (using `sss2`).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36a4cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=0)\n",
    "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.112, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74a07ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, dev_index in sss.split(abortion_data, abortion_stance):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_dev = abortion_data[train_index], abortion_data[dev_index]\n",
    "    y_train, y_dev = abortion_stance[train_index], abortion_stance[dev_index]\n",
    "    \n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    \n",
    "    for train_index, test_index in sss2.split(X_train, y_train):\n",
    "        X_train, X_test = X_train[train_index], X_train[test_index]\n",
    "        y_train, y_test = y_train[train_index], y_train[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9151531a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>Sorry- I forgot that this was HTML format...I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>So it is metaphysical independence that create...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>Risk-taking and disorders lead to abortions; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>This is what it comes down to. Government is h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>So you think it is a baby, the moment the sper...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0                                                  1\n",
       "422  __label__2  Sorry- I forgot that this was HTML format...I ...\n",
       "437  __label__2  So it is metaphysical independence that create...\n",
       "492  __label__1   Risk-taking and disorders lead to abortions; ...\n",
       "182  __label__2  This is what it comes down to. Government is h...\n",
       "913  __label__1  So you think it is a baby, the moment the sper..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenation of data and stance label; flair requires the label to be in column 0 and the data to be in column 1\n",
    "train_df = pd.concat([y_train, X_train], axis=1)\n",
    "dev_df = pd.concat([y_dev, X_dev], axis=1)\n",
    "test_df = pd.concat([y_test, X_test], axis=1)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608e7e4b",
   "metadata": {},
   "source": [
    "We save training, development and testing set and will load it again in notebook part II."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f69d52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(train_path, sep='\\t', index = False, header = False)\n",
    "dev_df.to_csv(dev_path, sep='\\t', index=False, header=False)\n",
    "test_df.to_csv(test_path, sep='\\t', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
