{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stance Detection in Tweets (Conforti Et Al 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will work with data that is part of the current largest Stance Detection dataset: the Twitter dataset Will-They-Won't-They, which was published in 2020 by Conforti et al.  \n",
    "\n",
    "In contrast to the notebook on Somasundaran & Wiebe 2010 we will explore a different type of features that can be used for stance detection: word/document embeddings. We will also work with more classification algorithms.\n",
    "\n",
    "The data set was presented and discussed in:\n",
    "\n",
    "Conforti et al (2020). Will-They-Wonâ€™t-They: A Very Large Dataset for Stance Detection on Twitter.\n",
    "https://www.aclweb.org/anthology/2020.acl-main.157/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/.virtualenvs/stance_course/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to be adjusted to your platform\n",
    "id_path = '/home/robin/research/corpora/acl2020-wtwt-tweets/wtwt_ids.json'\n",
    "corpus_path = '/home/robin/research/corpora/acl2020-wtwt-tweets/tweets/tweets_final.json'\n",
    "\n",
    "X_path = '/home/robin/research/corpora/acl2020-wtwt-tweets/X_array.npy'\n",
    "X_stance_path = '/home/robin/research/corpora/acl2020-wtwt-tweets/X_stance_array.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Having a look at the IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tweet IDs can be cloned from Github: https://github.com/cambridge-wtwt/acl2020-wtwt-tweets\n",
    "\n",
    "The IDs are in the file: wtwt_ids.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51284\n"
     ]
    }
   ],
   "source": [
    "with io.open(id_path, mode='r') as f_in:\n",
    "    corpus = json.load(f_in)\n",
    "    \n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first entry:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tweet_id': '971761970117357568', 'merger': 'CI_ESRX', 'stance': 'support'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The first entry:')\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to strict data privacy regulations the actual Tweet content can not be distributed. In order to use the corpus, one has to collect the tweets using the IDs. In a second step, one has to match the IDs with the respective stance label. To facilitate the matching step we restructure the corpus such that we can access the labels via the respective ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'merger': 'CI_ESRX', 'stance': 'support'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_restructured = {}\n",
    "for entry in corpus:\n",
    "    corpus_restructured[entry['tweet_id']] = {'merger': entry['merger'], 'stance': entry['stance']}\n",
    "\n",
    "corpus_restructured['971761970117357568']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Collecting the Tweet data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to collect tweets via the Twitter API. I recommend using Tweepy as it is a high level tool that makes the task quite easy. \n",
    "\n",
    "https://www.tweepy.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you may use a simple tweet crawler tool that I wrote. It is based on Tweepy and even more high level.\n",
    "\n",
    "https://github.com/RobinSchaefer/tweet-crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any case you will need to get your own Twitter Developer credentials. These allow you to access the API.\n",
    "\n",
    "https://developer.twitter.com/en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the Actual Tweet Data + Matching With Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we load the actual tweet data and match them with their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again: you need to collect the tweets first and set corpus_path\n",
    "with io.open(corpus_path, mode='r') as f_in:\n",
    "    tweets_json = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number support tweets: 2891\n",
      "Number refute tweets: 1229\n",
      "Number comment tweets: 10668\n",
      "Number unrelated tweets: 0\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "labels = []\n",
    "support_tweets = 0\n",
    "refute_tweets = 0\n",
    "comment_tweets = 0\n",
    "unrelated_tweets = 0\n",
    "\n",
    "stance_tweets = []\n",
    "stance_labels = []\n",
    "\n",
    "for tweet in tweets_json:\n",
    "    id_ = tweet['id_str']\n",
    "    text = tweet['full_text']\n",
    "    label = corpus_restructured[id_]['stance']\n",
    "    \n",
    "    tweets.append(text)\n",
    "    labels.append(label)\n",
    "    \n",
    "    if label == 'support':\n",
    "        support_tweets += 1\n",
    "        stance_tweets.append(text)\n",
    "        stance_labels.append(label)\n",
    "    elif label == 'refute':\n",
    "        refute_tweets += 1\n",
    "        stance_tweets.append(text)\n",
    "        stance_labels.append(label)\n",
    "    elif label == 'comment':\n",
    "        comment_tweets += 1   \n",
    "        stance_tweets.append(text)\n",
    "        stance_labels.append(label)\n",
    "    elif label == 'unrelated':\n",
    "        comment_tweets += 1\n",
    "\n",
    "print('Number support tweets: {}'.format(support_tweets))\n",
    "print('Number refute tweets: {}'.format(refute_tweets))\n",
    "print('Number comment tweets: {}'.format(comment_tweets))\n",
    "print('Number unrelated tweets: {}'.format(unrelated_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating Embedding Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For embedding creation we use Flair, in particular the `TransformerDocumentEmbeddings` class. We need this class to make use of pretrained BERT embeddings. Here we use 'bert-based-cased'.\n",
    "\n",
    "Flair allows for different embedding types, both for words and documents, which can be easily applied.\n",
    "\n",
    "For the documentation and heplful tutorials see: https://github.com/flairNLP/flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "embedder = TransformerDocumentEmbeddings('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the next code block we can encode a text string simply by using the `.embed()` method of our embedder object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Embeddings: 1000\n",
      "Generated Embeddings: 2000\n",
      "Generated Embeddings: 3000\n",
      "Generated Embeddings: 4000\n",
      "Generated Embeddings: 5000\n",
      "Generated Embeddings: 6000\n",
      "Generated Embeddings: 7000\n",
      "Generated Embeddings: 8000\n",
      "Generated Embeddings: 9000\n",
      "Generated Embeddings: 10000\n",
      "Generated Embeddings: 11000\n",
      "Generated Embeddings: 12000\n",
      "Generated Embeddings: 13000\n",
      "Generated Embeddings: 14000\n"
     ]
    }
   ],
   "source": [
    "# Embeddings for total data set\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for i, text in enumerate(tweets):\n",
    "    text = Sentence(text)\n",
    "\n",
    "    embedder.embed(text)\n",
    "    embedded = text.embedding.data.numpy()\n",
    "    embeddings.append(list(embedded))\n",
    "\n",
    "    if (i+1) % 1000 == 0:\n",
    "        print('Generated Embeddings: {}'.format(i+1))\n",
    "\n",
    "X = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Embeddings: 1000\n",
      "Generated Embeddings: 2000\n",
      "Generated Embeddings: 3000\n",
      "Generated Embeddings: 4000\n",
      "Generated Embeddings: 5000\n",
      "Generated Embeddings: 6000\n",
      "Generated Embeddings: 7000\n",
      "Generated Embeddings: 8000\n",
      "Generated Embeddings: 9000\n",
      "Generated Embeddings: 10000\n"
     ]
    }
   ],
   "source": [
    "# Embeddings for support/refute data set\n",
    "\n",
    "embeddings_stance = []\n",
    "\n",
    "for i, text in enumerate(stance_tweets):\n",
    "    text = Sentence(text)\n",
    "\n",
    "    embedder.embed(text)\n",
    "    embedded = text.embedding.data.numpy()\n",
    "    embeddings_stance.append(list(embedded))\n",
    "\n",
    "    if (i+1) % 1000 == 0:\n",
    "        print('Generated Embeddings: {}'.format(i+1))\n",
    "\n",
    "X_stance = np.array(embeddings_stance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As creating document embeddings takes some time, we save our features for future steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(X_path,X)\n",
    "np.save(X_stance_path, X_stance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once created and saved we can easily load them using `np.load`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data array size: (14788, 768)\n"
     ]
    }
   ],
   "source": [
    "X = np.load(X_path)\n",
    "print('Data array size: {}'.format(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data array size: (10381, 768)\n"
     ]
    }
   ],
   "source": [
    "X_stance = np.load(X_stance_path)\n",
    "print('Data array size: {}'.format(X_stance.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Testing Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the notebook on Somasundaran & Wiebe 2010 we split the data into training and testing sets. We then initialize different classification models, fit them and use them for prediction. For evaluation we use macro f1 scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining models\n",
    "\n",
    "svm_classifier = SVC()\n",
    "naive_bayes_classifier = GaussianNB()\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "adaboost_classifier = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting models\n",
    "\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "naive_bayes_classifier.fit(X_train, y_train)\n",
    "decision_tree_classifier.fit(X_train, y_train)\n",
    "adaboost_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing models\n",
    "\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "y_pred_naive_bayes = naive_bayes_classifier.predict(X_test)\n",
    "y_pred_decision_tree = decision_tree_classifier.predict(X_test)\n",
    "y_pred_adaboost = adaboost_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score SVM: 0.475\n",
      "F1 Score Naive Bayes: 0.432\n",
      "F1 Score Decision Tree: 0.395\n",
      "F1 Score AdaBoost: 0.485\n"
     ]
    }
   ],
   "source": [
    "# Evaluating models\n",
    "\n",
    "f1_svm = f1_score(y_test, y_pred_svm, average='macro')\n",
    "print(\"F1 Score SVM: {}\".format(round(f1_svm,3)))\n",
    "f1_naive_bayes = f1_score(y_test, y_pred_naive_bayes, average='macro')\n",
    "print(\"F1 Score Naive Bayes: {}\".format(round(f1_naive_bayes, 3)))\n",
    "f1_decision_tree = f1_score(y_test, y_pred_decision_tree, average='macro')\n",
    "print(\"F1 Score Decision Tree: {}\".format(round(f1_decision_tree, 3)))\n",
    "f1_adaboost = f1_score(y_test, y_pred_adaboost, average='macro')\n",
    "print(\"F1 Score AdaBoost: {}\".format(round(f1_adaboost, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Support/Refute Dataset (more balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stance_train, X_stance_test, y_stance_train, y_stance_test = train_test_split(X_stance, stance_labels, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier_stance = SVC()\n",
    "naive_bayes_classifier_stance = GaussianNB()\n",
    "decision_tree_classifier_stance = DecisionTreeClassifier()\n",
    "adaboost_classifier_stance = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier_stance.fit(X_stance_train, y_stance_train)\n",
    "naive_bayes_classifier_stance.fit(X_stance_train, y_stance_train)\n",
    "decision_tree_classifier_stance.fit(X_stance_train, y_stance_train)\n",
    "adaboost_classifier_stance.fit(X_stance_train, y_stance_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_stance_pred_svm = svm_classifier_stance.predict(X_stance_test)\n",
    "y_stance_pred_naive_bayes = naive_bayes_classifier_stance.predict(X_stance_test)\n",
    "y_stance_pred_decision_tree = decision_tree_classifier_stance.predict(X_stance_test)\n",
    "y_stance_pred_adaboost = adaboost_classifier_stance.predict(X_stance_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score SVM: 0.469\n",
      "F1 Score Naive Bayes: 0.556\n",
      "F1 Score Decision Tree: 0.478\n",
      "F1 Score AdaBoost: 0.554\n"
     ]
    }
   ],
   "source": [
    "f1_svm_stance = f1_score(y_stance_test, y_stance_pred_svm, average='macro')\n",
    "print(\"F1 Score SVM: {}\".format(round(f1_svm_stance,3)))\n",
    "f1_naive_bayes_stance = f1_score(y_stance_test, y_stance_pred_naive_bayes, average='macro')\n",
    "print(\"F1 Score Naive Bayes: {}\".format(round(f1_naive_bayes_stance, 3)))\n",
    "f1_decision_tree_stance = f1_score(y_stance_test, y_stance_pred_decision_tree, average='macro')\n",
    "print(\"F1 Score Decision Tree: {}\".format(round(f1_decision_tree_stance, 3)))\n",
    "f1_adaboost_stance = f1_score(y_stance_test, y_stance_pred_adaboost, average='macro')\n",
    "print(\"F1 Score AdaBoost: {}\".format(round(f1_adaboost_stance, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification results of both data sets show a substantial difference. What could lead to these differences?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
